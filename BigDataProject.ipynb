{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will clean the documents and then we use K-fold for cross-validation to get the optimal fold then we choose the best modal between SVM, KNN, Naive Bayes(Gaussian) we will get that SVM as the best modal then we use GridsearchCV on SVM to get the best parameters of this modal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing tools:\n",
    "First of all we import our libraries the we will use in our projet like in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import collections\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the required datasets:\n",
    "To use NLTK (Natural Language ToolKit) we need to download the following datasets to use them for preprocessing (tokenization,stopwords,lemmatization...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ami\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ami\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ami\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the data folder:\n",
    "we start by reading the CSV files to retrieve the files that hasn't a class yet to move them into a new folder so that the classification process will be good as the train.csv file. as a result we get **(4800 file that is in the folder data and 200 in test_set folder).** the function bellow is only executed on the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning process:\n",
    "In this process firt of all we parse each XML file then we tokenize it so that it will be represented as a list in python then we lemmatize each word and then we do the stemming process to get the word stem, So the variable **cleaned_docs** will contains a list of document that we cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################# docs that we are going to train on####################\n",
    "df = pd.read_csv('train.csv',delimiter=\",\")\n",
    "files=df['file']\n",
    "Y=df['earnings: 0 no/ 1 yes']\n",
    "cleaned_docs=[]\n",
    "for f in files:\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    s=open(\"data/\"+f,\"r\")\n",
    "    dom = ET.parse(s)\n",
    "    root = dom.getroot()\n",
    "    doc_word=str(root.text)\n",
    "    token = word_tokenize(doc_word)\n",
    "    clean_tokens = []\n",
    "    for word in token:\n",
    "        clean_tokens.append(stemmer.stem(lemmatiser.lemmatize(word)))\n",
    "    s = ' '.join(clean_tokens)\n",
    "    cleaned_docs.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################### docs to predict their classes######################\n",
    "df = pd.read_csv('test.csv',delimiter=\",\")\n",
    "files=df['file']\n",
    "docs=[]\n",
    "for f in files:\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    s=open(\"data/\"+f,\"r\")\n",
    "    dom = ET.parse(s)\n",
    "    root = dom.getroot()\n",
    "    doc_word=str(root.text)\n",
    "    token = word_tokenize(doc_word)\n",
    "    clean_tokens = []\n",
    "    for word in token:\n",
    "        clean_tokens.append(stemmer.stem(lemmatiser.lemmatize(word)))\n",
    "    s = ' '.join(clean_tokens)\n",
    "    docs.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction (TF-IDF):\n",
    "in order to get features from our text files we user this scikit function to tokenize and calculate TF-iDF of each word at the \n",
    "end the variables **X** and **docs** will contains \n",
    "\n",
    "a matrix **(docs-features)** of TF-IDF values such as **X** will be the our dataset with it's known classes and **docs** the dataset of docs that we will predict its classes.\n",
    "\n",
    "**TFIDFVectorizer params:**\n",
    "* **min_df=10 :** remove terms that apears in less than 10 documents.\n",
    "* **max_df=0.9 :** remove terms that apears in more than 90% of documents.\n",
    "* **stop_words:** takes a stop words list to remove them from documents.\n",
    "* **ngram_range:** takes an interval of the number of words in a sequence.\n",
    "* **lowercase:** true to turn all terms to lowercase.\n",
    "* **token_pattern:** takes a regular expression to remove everything that is not alphabetic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(stop_words=stopwords.words('english'),min_df=10,max_df=0.9,ngram_range=(1,2),lowercase=True,token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    ")\n",
    "tfidf.fit(cleaned_docs)\n",
    "X=tfidf.transform(cleaned_docs).toarray()\n",
    "docs=tfidf.transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 5398)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # we had 5398 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting training/test sets:\n",
    "We split the our dataset into training set and test set and we used the default parameters so that we will have 75% (3600 docs)of training set and 25% (1200 docs) of test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y) # split test set=> 25% and train set 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the right model:\n",
    "we have selected three models that we will use to determine which one is better using K-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names=[\"svm\",\"knn\",\"naiveBayes\"]\n",
    "clfs=[SVC(C=1.0,kernel='linear'),KNeighborsClassifier(n_neighbors=5),GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=4, random_state=None, shuffle=False)\n",
      "TRAIN: [1200 1201 1202 ... 4797 4798 4799] TEST: [   0    1    2 ... 1197 1198 1199]\n",
      "Model-name:svm Score:0.9466666666666667\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:knn Score:0.9375\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:naiveBayes Score:0.8666666666666667\n",
      "Accuracy: 0.87 (+/- 0.01)\n",
      "TRAIN: [   0    1    2 ... 4797 4798 4799] TEST: [1200 1201 1202 ... 2397 2398 2399]\n",
      "Model-name:svm Score:0.9691666666666666\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:knn Score:0.9591666666666666\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:naiveBayes Score:0.8683333333333333\n",
      "Accuracy: 0.87 (+/- 0.01)\n",
      "TRAIN: [   0    1    2 ... 4797 4798 4799] TEST: [2400 2401 2402 ... 3597 3598 3599]\n",
      "Model-name:svm Score:0.9716666666666667\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:knn Score:0.9683333333333334\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:naiveBayes Score:0.8783333333333333\n",
      "Accuracy: 0.87 (+/- 0.01)\n",
      "TRAIN: [   0    1    2 ... 3597 3598 3599] TEST: [3600 3601 3602 ... 4797 4798 4799]\n",
      "Model-name:svm Score:0.965\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:knn Score:0.955\n",
      "Accuracy: 0.96 (+/- 0.02)\n",
      "Model-name:naiveBayes Score:0.8633333333333333\n",
      "Accuracy: 0.87 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    for name,clf in zip(names,clfs):\n",
    "        print(\"Model-name:\"+name+\" Score:\"+str(clf.fit(X_train,y_train).score(X_test,y_test)))\n",
    "        scores = cross_val_score(clf, X, labels, cv=4)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV:\n",
    "After that we saw that SVM beats all the classifier in the score and accuracy and we get the right splits the 3rd fold of the dataset which can make the classifier reach a higher score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'C':[1, 10]}\n",
    "clf=SVC(kernel=\"linear\")\n",
    "clf = GridSearchCV(clf, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1, param_grid={'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model:\n",
    "We use the methods below to compute and evaluate our model so at the end we get the optimal precesion, recall and f1-measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.965\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \"+str(clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[928  12]\n",
      " [ 30 230]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       940\n",
      "          1       0.95      0.88      0.92       260\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1200\n",
      "\n",
      "0.965\n"
     ]
    }
   ],
   "source": [
    "p=clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,p))  \n",
    "print(classification_report(y_test,p))  \n",
    "print(accuracy_score(y_test, p))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of the documents:\n",
    "Now we predict the labels of the given docs we will get something similar to this for each doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 150, 1: 50})"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=clf.predict(docs)\n",
    "collections.Counter(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our prediction in test.csv:\n",
    "After we predict tests documents we save the predictions in the thirds column of the test.csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['earnings: 0 no/ 1 yes']=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the modal:\n",
    "to use the classifier directly without loosing time and retraining the model we save it in a file then when we need to use it we just load it as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_classifier.joblib']"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, 'SVM_classifier.joblib') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=load('SVM_classifier.joblib') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis:\n",
    "In this part we're going to use PCA(Principal Component Analysis) to reduce the dimensionality of the datasets and then we will use K-means for clustering(unsupervised classification) then we can know if there's truly two classes or more than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08269211 0.04384641]\n",
      "[19.51884537 14.21310989]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)                 \n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0061672  0.00507547]\n",
      "[399.74322802 362.63954402]\n"
     ]
    }
   ],
   "source": [
    "pca.fit(X_std)\n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
